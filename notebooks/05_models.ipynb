{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 15:19:11,064 - root - INFO - ** Kedro project Immunization Drop-outs\n",
      "2020-06-08 15:19:11,065 - root - INFO - Defined global variable `context` and `catalog`\n"
     ]
    }
   ],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 15:19:11,069 - kedro.io.data_catalog - INFO - Loading data from `model_table` (CSVDataSet)...\n"
     ]
    }
   ],
   "source": [
    "dfm = catalog.load(\"model_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fix a baseline to see whether we are developing useful models or not, a baseline classifier always predicts the majority class. It's the simplest classifier we could build.\n",
    "\n",
    "The majority class represents a 60.9% of the whole dataset (`high`). For that reason, that would be the accuracy of a majority class classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-08 15:19:11,102 - kedro.io.data_catalog - INFO - Loading data from `X_train` (PickleDataSet)...\n",
      "2020-06-08 15:19:11,105 - kedro.io.data_catalog - INFO - Loading data from `y_train` (PickleDataSet)...\n",
      "2020-06-08 15:19:11,106 - kedro.io.data_catalog - INFO - Loading data from `X_test` (PickleDataSet)...\n",
      "2020-06-08 15:19:11,107 - kedro.io.data_catalog - INFO - Loading data from `y_test` (PickleDataSet)...\n"
     ]
    }
   ],
   "source": [
    "features_train = catalog.load(\"X_train\")\n",
    "labels_train = catalog.load(\"y_train\")\n",
    "features_test = catalog.load(\"X_test\")\n",
    "labels_test = catalog.load(\"y_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36540, 7)\n",
      "(9135, 7)\n"
     ]
    }
   ],
   "source": [
    "print(features_train.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation for Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 8,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "rf_0 = RandomForestClassifier(random_state = 8)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf_0.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll tune the following ones:\n",
    "* n_estimators = number of trees in the forest.\n",
    "* max_features = max number of features considered for splitting a node\n",
    "* max_depth = max number of levels in each decision tree\n",
    "* min_samples_split = min number of data points placed in a node before the node is split\n",
    "* min_samples_leaf = min number of data points allowed in a leaf node\n",
    "* bootstrap = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "n_estimators = [int(x) for x in np.linspace(start = 20, stop = 100, num = 5)]\n",
    "\n",
    "# max_features\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "# max_depth\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# min_samples_split\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "# min_samples_leaf\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "# bootstrap\n",
    "bootstrap = [True, False]\n",
    "\n",
    "#n_jobs\n",
    "n_jobs = [4]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "              'n_jobs': n_jobs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [20, 40, 60, 80, 100],\n",
      " 'n_jobs': [4]}\n"
     ]
    }
   ],
   "source": [
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the Random Search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:   10.5s\n",
      "[Parallel(n_jobs=4)]: Done 150 out of 150 | elapsed:   43.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score=nan,\n",
       "                   estimator=RandomForestClassifier(bootstrap=True,\n",
       "                                                    ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features='auto',\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    max_samples=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    n_estimators=100,\n",
       "                                                    n_jobs...\n",
       "                   iid='deprecated', n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [20, 40, 60, 80, 100],\n",
       "                                        'n_jobs': [4]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=8, refit=True,\n",
       "                   return_train_score=False, scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the base model to tune\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Definition of the random search\n",
    "random_search = RandomizedSearchCV(estimator=rfc,\n",
    "                                   param_distributions=random_grid,\n",
    "                                   n_iter=50,\n",
    "                                   scoring='accuracy',\n",
    "                                   cv=3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8,\n",
    "                                  n_jobs=4)\n",
    "\n",
    "# Fit the random search model\n",
    "random_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Random Search are:\n",
      "{'n_jobs': 4, 'n_estimators': 80, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 10, 'bootstrap': False}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.8727422003284072\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Random Search are:\")\n",
    "print(random_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(random_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.RandomizedSearchCV"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=4)]: Done  81 out of  81 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=3, random_state=8, test_size=0.33, train_size=None),\n",
       "             error_score=nan,\n",
       "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                                              class_weight=None,\n",
       "                                              criterion='gini', max_depth=None,\n",
       "                                              max_features='auto',\n",
       "                                              max_leaf_nodes=None,\n",
       "                                              max_samples=None,\n",
       "                                              min_impurity_decrease=0.0,\n",
       "                                              min_impurity_split=None,\n",
       "                                              min_samples_leaf=1,\n",
       "                                              min_sampl...\n",
       "                                              n_estimators=100, n_jobs=None,\n",
       "                                              oob_score=False, random_state=8,\n",
       "                                              verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'bootstrap': [False], 'max_depth': [30, 40, 50],\n",
       "                         'max_features': ['sqrt'],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [5, 10, 15],\n",
       "                         'n_estimators': [800], 'n_jobs': [4]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=1)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the parameter grid based on the results of random search \n",
    "bootstrap = [False]\n",
    "max_depth = [30, 40, 50]\n",
    "max_features = ['sqrt']\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_samples_split = [5, 10, 15]\n",
    "n_estimators = [800]\n",
    "n_jobs = [4]\n",
    "\n",
    "param_grid = {\n",
    "    'bootstrap': bootstrap,\n",
    "    'max_depth': max_depth,\n",
    "    'max_features': max_features,\n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_samples_split': min_samples_split,\n",
    "    'n_estimators': n_estimators,\n",
    " 'n_jobs': [4]\n",
    "}\n",
    "\n",
    "# Create a base model\n",
    "rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "# Manually create the splits in CV in order to be able to fix a random_state \n",
    "#(GridSearchCV doesn't have that argument) \n",
    "cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rfc, \n",
    "                           param_grid=param_grid,\n",
    "                           scoring='accuracy',\n",
    "                           cv=cv_sets,\n",
    "                           verbose=1,\n",
    "                                  n_jobs=4)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters from Grid Search are:\n",
      "{'bootstrap': False, 'max_depth': 40, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 15, 'n_estimators': 800, 'n_jobs': 4}\n",
      "\n",
      "The mean accuracy of a model with these hyperparameters is:\n",
      "0.8643613345495756\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters from Grid Search are:\")\n",
    "print(grid_search.best_params_)\n",
    "print(\"\")\n",
    "print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best model \n",
    "best_rfc = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=40, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=15,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=4,\n",
       "                       oob_score=False, random_state=8, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets fit it and see how it performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning_randomized_search():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 20, stop = 100, num = 5)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 50, num = 5)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    n_jobs = [4]\n",
    "\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap,\n",
    "                   'n_jobs': n_jobs}\n",
    "    \n",
    "    # Create the base model to tune\n",
    "    rfc = RandomForestClassifier(random_state=8)\n",
    "    # Definition of the random search\n",
    "    random_search = RandomizedSearchCV(estimator=rfc,\n",
    "                                       param_distributions=random_grid,\n",
    "                                       n_iter=50,\n",
    "                                       scoring='accuracy',\n",
    "                                       cv=3, \n",
    "                                       verbose=1, \n",
    "                                       random_state=8,\n",
    "                                       n_jobs=4)\n",
    "    # Fit the random search model\n",
    "    random_search.fit(features_train, labels_train)\n",
    "    \n",
    "    print(\"The best hyperparameters from Random Search are:\")\n",
    "    print(random_search.best_params_)\n",
    "    print(\"\")\n",
    "    print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "    print(random_search.best_score_)\n",
    "    \n",
    "    # best model \n",
    "    best_rfc = random_search.best_estimator_\n",
    "    \n",
    "    return best_rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_tuning_grid():\n",
    "    \n",
    "    bootstrap = [False]\n",
    "    max_depth = [30, 40, 50]\n",
    "    max_features = ['sqrt']\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    min_samples_split = [5, 10, 15]\n",
    "    n_estimators = [800]\n",
    "    n_jobs = [4]\n",
    "\n",
    "    param_grid = {\n",
    "        'bootstrap': bootstrap,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'n_estimators': n_estimators,\n",
    "     'n_jobs': [4]\n",
    "    }\n",
    "\n",
    "    # Create a base model\n",
    "    rfc = RandomForestClassifier(random_state=8)\n",
    "    # Manually create the splits in CV \n",
    "    cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=rfc, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=cv_sets,\n",
    "                               verbose=1,\n",
    "                                      n_jobs=4)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(features_train, labels_train)\n",
    "    print(\"The best hyperparameters from Grid Search are:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print(\"\")\n",
    "    print(\"The mean accuracy of a model with these hyperparameters is:\")\n",
    "    print(grid_search.best_score_)\n",
    "    \n",
    "    # best model \n",
    "    best_rfc = grid_search.best_estimator_\n",
    "    \n",
    "    return best_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fit and performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=40, max_features='sqrt',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=15,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=4,\n",
       "                       oob_score=False, random_state=8, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rfc.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_pred = best_rfc.predict(features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, ..., 1, 0, 1])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.,   1.,   0., ...,   3.,   3.,   3.],\n",
       "       [278.,   1.,   1., ...,   2.,   3.,   0.],\n",
       "       [257.,   1.,   0., ...,   1.,   1.,   6.],\n",
       "       ...,\n",
       "       [251.,   1.,   0., ...,   3.,   4.,   0.],\n",
       "       [307.,   1.,   1., ...,   1.,   2.,   0.],\n",
       "       [288.,   1.,   0., ...,   1.,   3.,   0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For performance analysis, I will use the confusion matrix, the classification report and the accuracy on both training and test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: \n",
      "0.8904761904761904\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is: \")\n",
    "print(accuracy_score(labels_train, best_rfc.predict(features_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test accuracy is: \n",
      "0.8561576354679803\n"
     ]
    }
   ],
   "source": [
    "print(\"The test accuracy is: \")\n",
    "print(accuracy_score(labels_test, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88      5576\n",
      "           1       0.81      0.82      0.82      3559\n",
      "\n",
      "    accuracy                           0.86      9135\n",
      "   macro avg       0.85      0.85      0.85      9135\n",
      "weighted avg       0.86      0.86      0.86      9135\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report\")\n",
    "print(classification_report(labels_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fit_and_performance(best_rfc, features_train, labels_train, features_test):\n",
    "    \"\"\"\n",
    "    For performance analysisthe confusion matrix, the classification report \n",
    "    and the accuracy on both training and test data\n",
    "    \"\"\"\n",
    "    best_rfc.fit(features_train, labels_train)\n",
    "    rfc_pred = best_rfc.predict(features_test)\n",
    "    \n",
    "    print(\"The training accuracy is: \")\n",
    "    print(accuracy_score(labels_train, best_rfc.predict(features_train)))\n",
    "    print(\"The test accuracy is: \")\n",
    "    print(accuracy_score(labels_test, rfc_pred))\n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(labels_test,rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kedro2",
   "language": "python",
   "name": "kedro2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
